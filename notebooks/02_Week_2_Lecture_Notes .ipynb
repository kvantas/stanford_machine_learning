{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Multiple Variables\n",
    "\n",
    "Linear regression with multiple variables is also known as \"multivariate linear regression\". We now introduce notation for equations where we can have any number of input variables.\n",
    "\n",
    "* $x_j(i)$ = value of feature j in the $i^{th}$ training example\n",
    "* $x(i)$ = the column vector of all the feature inputs of the $i^{th}$ training example\n",
    "* $m$ = the number of training examples\n",
    "* $n=|x(i)|$ the number of features\n",
    "\n",
    "Now define the multivariable form of the hypothesis function as follows, accommodating these multiple features:\n",
    "\n",
    "$$ h_\\theta (x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3 + \\cdots + \\theta_n x_n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to develop intuition about this function, we can think about $\\theta_0$ as the basic price of a house, $\\theta_1$ as the price per square meter, $\\theta_2$ as the price per floor, etc. $x_1$ will be the number of square meters in the house, $x_2$ the number of floors, etc.\n",
    "\n",
    "Using the definition of matrix multiplication, our multivariable hypothesis function can be concisely represented as:\n",
    "\n",
    "\\begin{equation}\n",
    "h_{\\theta}(x) = \n",
    "\\begin{bmatrix} \n",
    "\\theta_0 \\hspace{2em}  \n",
    "\\theta_1 \\hspace{2em}  \n",
    "...  \\hspace{2em}  \n",
    "\\theta_n\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_0 \\\\ \n",
    "x_1 \\\\ \n",
    "\\vdots \\\\ \n",
    "x_n\n",
    "\\end{bmatrix} \n",
    "= \\theta^T x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a vectorization of our hypothesis function for one training example; see the lessons on vectorization to learn more.\n",
    "\n",
    "Remark: Note that for convenience reasons in this course Mr. Ng assumes $x_0^{(i)}=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training examples are stored in X row-wise, like such:\n",
    "\n",
    "\\begin{equation}\n",
    "X = \n",
    "\\begin{bmatrix} \n",
    "x^{(1)}_0 & x^{(1)}_1  \\\\\n",
    "x^{(2)}_0 & x^{(2)}_1  \\\\\n",
    "x^{(3)}_0 & x^{(3)}_1 \\\\\n",
    "\\end{bmatrix},\n",
    "\\theta = \n",
    "\\begin{bmatrix}\n",
    "\\theta_0 \\\\\n",
    "\\theta_1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can calculate the hypothesis as a column vector of size (m x 1) with:\n",
    "\\begin{equation}\n",
    "h_\\theta(X) = X \\theta\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "For the parameter vector $\\theta$ the cost function is:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\theta) = \\frac {1}{2m}  \\sum_{i=1}^m \\left (h_\\theta (x^{(i)}) - y^{(i)} \\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "The vectorized version is:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\theta) = \\frac {1}{2m} (X\\theta - \\vec{y})^{T} (X\\theta - \\vec{y})\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\vec y$ denotes the vector of all y values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent for Multiple Variables\n",
    "\n",
    "The gradient descent equation itself is generally the same form; we just have to repeat it for our $n$ features:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} \\;  \\text{for j := 0...n}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
